{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afe89f1-7451-4d61-88fe-082783325aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras # Need this when working in a Jupyter notebook\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential # Model used to create the architecture both ANNs and CNNs\n",
    "from keras.layers.core import Dense \n",
    "# from keras.optimizers import SGD \n",
    "from tensorflow.keras.optimizers import SGD # Use the above instead in GCP. Colab can use the previous line.\n",
    "from keras.layers.convolutional import Conv2D # For CNNs\n",
    "from keras.layers.convolutional import MaxPooling2D # For CNNs\n",
    "from keras.layers.core import Flatten # For CNNs\n",
    "from keras.layers.core import Activation # For CNNs\n",
    "from keras.layers.core import Dropout # For CNNs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os as os\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from scipy import ndimage\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ea153-d15c-4f43-a15a-de588f6cdbf8",
   "metadata": {},
   "source": [
    "Bucket mount instruction in image preparation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db673fbc-e213-443f-93d7-9e625b70c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'gcs/resize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969f6c0d-fe68-4e37-b87d-f8b37cf1d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "cd ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4253dd84-5abb-4548-90f7-5a42a68941ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dragon_snake', 'flower', 'fox_tiger', 'mix', 'small_animal']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = os.listdir(dataDir)\n",
    "objects = objects[1:]\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62645bd6-784e-4a4b-b4ca-b2591229b5c0",
   "metadata": {},
   "source": [
    "# Binarizing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f32c5-77ba-40cb-b41a-590a30dcb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedArrayLabels = []\n",
    "stackedArrayLabels.append(objects[1])\n",
    "print(stackedArrayLabels)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "binarizedLabels = lb.fit_transform(stackedArrayLabels)\n",
    "print(binarizedLabels)\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa42aeb-e1d3-48ed-a58f-80b0fa2ab089",
   "metadata": {},
   "source": [
    "The binarized label doesn't work as intended because there's only one image to binarize it's label. If all images were included in the binarization then the binarized labels should look like \n",
    "\n",
    "$\\big[$0, 1, 0, 0, 0$\\big]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54680d-10b1-45f0-81d6-575358d5a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedArrayValues = [] # Normalised, resized and stacked 1D arrays corresponding to the images.\n",
    "stackedArrayLabels = [] # 1D array for the labels.\n",
    "\n",
    "# Finding all the sources in each object that ends with `imageType_*.jpg`.\n",
    "for imageType in objects:\n",
    "    folder = os.path.abspath(dataDir + '/' + imageType)\n",
    "    files = glob.glob(folder + '/' + imageType + '_*.jpg')\n",
    "\n",
    "# For each source, we want to resize and normalise the image.\n",
    "    for filename in files:\n",
    "        data = plt.imread(filename)\n",
    "\n",
    "        # Normalisation is done by first subtracting the minimum value, and then dividing by the maximum value in the subtracted values.\n",
    "        normalisedData = (data - np.min(data))/np.max(data - np.min(data))\n",
    "        normalised1D = normalisedData.flatten() # Turning the 2D image into a 1D array.\n",
    "        stackedArrayValues.append(normalised1D)\n",
    "        stackedArrayLabels.append(imageType)\n",
    "    print(f'object {imageType} complete')\n",
    "# Converting the lists into a 1D array.\n",
    "stackedArrayValues = np.array(stackedArrayValues)\n",
    "stackedArrayLabels = np.array(stackedArrayLabels)\n",
    "\n",
    "# Binarising the labels once all the sources for each object were identified, resized and normalised:\n",
    "lb = LabelBinarizer()\n",
    "binarizedLabels = lb.fit_transform(stackedArrayLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae652cd-8afc-4015-9652-2017ce2c4375",
   "metadata": {},
   "source": [
    "# ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745d885-dbe4-4610-8c11-66b9f21dd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee64f3-c5c1-4b19-bed8-82440fa51019",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedArrayValues = [] # Normalised, resized and stacked 1D arrays corresponding to the images.\n",
    "stackedArrayLabels = [] # 1D array for the labels.\n",
    "\n",
    "# Finding all the sources in each object that ends with `_I4.fits`.\n",
    "folder = os.path.abspath(dataDir + '/' + objects[0])\n",
    "files = glob.glob(folder + '/' + objects[0] + '_*.jpg')\n",
    "\n",
    "# For each source, we want to resize and normalise the image.\n",
    "for filename in files:\n",
    "  data = plt.imread(filename)\n",
    "  # resizeData = ndimage.zoom(data,zoom=zoom_factor) \n",
    "\n",
    "  # Normalisation is done by first subtracting the minimum value, and then dividing by the maximum value in the subtracted values.\n",
    "  normalisedData = (data-np.min(data))/np.max(data-np.min(data))\n",
    "  normalised1D = normalisedData.flatten() # Turning the 2D image into a 1D array.\n",
    "  stackedArrayValues.append(normalised1D)\n",
    "  stackedArrayLabels.append(imageType)\n",
    "\n",
    "# Converting the lists into a 1D array.\n",
    "stackedArrayValues = np.array(stackedArrayValues)\n",
    "stackedArrayLabels = np.array(stackedArrayLabels)\n",
    "\n",
    "# Binarising the labels once all the sources for each object were identified, resized and normalised:\n",
    "lb = LabelBinarizer()\n",
    "binarizedLabels = lb.fit_transform(stackedArrayLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d98560-1945-422f-966e-70e430623487",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPrepANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f8773-e6cf-44a8-a948-c6da2cfc3fb2",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860040d-5a76-4c62-ad56-f5a107c1c429",
   "metadata": {},
   "source": [
    "for cnn have to consider the astro objects had 3 different wavelenghts for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371008f7-da9b-48ee-9f58-8827ae24610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnPrepFn(directory, source_type, rotation_factor):\n",
    "  # Similar initial process as the ANN function:\n",
    "  files = glob.glob(directory + '/' + source_type+'/'+'*_I4.fits')\n",
    "  # The amount of zooming for the images will impact the image's dimensions.\n",
    "  # Since 302x302 is the original size of the images, we want the dimension of the zoomed-in images which depends on the zoom factor.\n",
    "  imagesArr = np.zeros((100,int(zoom_factor*302),int(zoom_factor*302),3)) \n",
    "  labelsList = [] # The labels will become a 1D array.\n",
    "\n",
    "  # Identifying the 3 images that will be resized and normalised:\n",
    "  for indx in np.arange(0,len(files)):\n",
    "    source = files[indx].split('_I4.fits')[0] # Finding the name for each source by splitting the string from `glob.glob` into two parts.\n",
    "                                              # We don't want the text starting from _, so we use [0] to get the source name only.\n",
    "    i2Image = plt.imread(source+'_I2.fits') # The I2 image for the source.\n",
    "\n",
    "    # Resizing the three Spitzer-band images above and finding the maximum value in each image:\n",
    "    resizeI2 = ndimage.rotate(i2Image, rotation_factor, reshape = False)\n",
    "    resizeI2Max = np.max(resizeI2)\n",
    "\n",
    "\n",
    "    # Normalisation is done by finding the greatest value in the maxima for each of the 3 images.\n",
    "    # This is so all the values are smaller than or equal to 1 (for the CNN), and maintain the colour differences between them.\n",
    "    normFactor = np.max([resizeI2Max, resizeI3Max, resizeI4Max])\n",
    "\n",
    "    # Applying the normalisation factor to the resized images:\n",
    "    normI2 = resizeI2/normFactor\n",
    "\n",
    "    # Adding the resized and normalised images into the iamge array:\n",
    "    imagesArr[indx,:,:,0] = normI2\n",
    "\n",
    "    # Adding the label that identifies the source type (HII, PNE, RG):\n",
    "    labelsList.append(source_type)\n",
    "\n",
    "  # Converting the list of labels into an array:\n",
    "  labelsArr = np.array(labelsList)\n",
    "\n",
    "  return imagesArr, labelsArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d20428-cdf8-4818-9161-afdf657ee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "HII_Images_0, HII_Labels_0 = cnnPrepFn2(dir, \"HII\", zoom_factor=0.6, rotation_factor= 0)\n",
    "PNE_Images_0, PNE_Labels_0 = cnnPrepFn2(dir, \"PNE\", zoom_factor=0.6, rotation_factor= 0)\n",
    "RG_Images_0, RG_Labels_0 = cnnPrepFn2(dir, \"RG\", zoom_factor=0.6, rotation_factor= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef07b23f-d6db-433d-ba74-18217c46ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_img_aug = np.concatenate((HII_Images_0, HII_Images_90, HII_Images_180, HII_Images_270, PNE_Images_0, PNE_Images_90, PNE_Images_180, PNE_Images_270, RG_Images_0, RG_Images_90, RG_Images_180, RG_Images_270), axis = 0)\n",
    "combined_labels_aug = np.concatenate((HII_Labels_0, HII_Labels_90, HII_Labels_180, HII_Labels_270, PNE_Labels_0, PNE_Labels_90, PNE_Labels_180, PNE_Labels_270, RG_Labels_0, RG_Labels_90, RG_Labels_180, RG_Labels_270), axis = 0)\n",
    "\n",
    "combined_img_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792b58d-3b36-4c2c-8138-cc4e76fa9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarising the labels for the CNN:\n",
    "lb = LabelBinarizer()\n",
    "combined_labels_aug = lb.fit_transform(combined_labels_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c74f41-b58f-46f0-a9ef-386fb371d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnFn(combinedImages, combinedLabels, layers: int, neurons: float, neuronsDescending: bool(), numEpochs: int, learnRate: float, momentum: float):\n",
    "  '''\n",
    "  layers = number of layers to add\n",
    "\n",
    "  neurons = integer from 0.5 to 2.0. Either halving or doubling the number of neurons. \n",
    "\n",
    "  numEpochs = number of epochs to train the model. \n",
    "  '''\n",
    "  \n",
    "  trainData, testData, trainLabels, testLabels = train_test_split(combinedImages, combinedLabels, test_size=0.3)\n",
    "\n",
    "  modelCNN = Sequential()\n",
    "  size = trainData.shape[1]\n",
    "  inputShape = (size, size, 3)\n",
    "\n",
    "  chanDim = -1\n",
    "  if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (size, size, 3)\n",
    "    chanDim = 1\n",
    "  \n",
    "  neurons = [neurons, neurons]\n",
    "\n",
    "  modelCNN.add(Conv2D(32*neurons[0], (3,3), input_shape = inputShape))\n",
    "  modelCNN.add(Activation('relu'))\n",
    "  modelCNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "  modelCNN.add(Conv2D(32*neurons[0], (3,3)))\n",
    "  modelCNN.add(Activation('relu'))\n",
    "  modelCNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "  if neuronsDescending == True:\n",
    "    neurons = [neurons[0]*0.5, neurons[1]*0.25]\n",
    "\n",
    "  modelCNN.add(Conv2D(64*neurons[0], (3,3))) \n",
    "  modelCNN.add(Activation('relu'))\n",
    "  modelCNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "  if layers == 1:\n",
    "    modelCNN.add(Conv2D(64*neurons[1], (3,3))) \n",
    "    modelCNN.add(Activation('relu'))\n",
    "    modelCNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "  if layers == 2:\n",
    "    modelCNN.add(Conv2D(64*neurons[1], (3,3))) \n",
    "    modelCNN.add(Activation('relu'))\n",
    "    modelCNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "  modelCNN.add(Flatten()) \n",
    "  modelCNN.add(Dense(64))\n",
    "  modelCNN.add(Activation('relu'))\n",
    "  modelCNN.add(Dropout(0.5))\n",
    "\n",
    "  nClasses = 3\n",
    "  modelCNN.add(Dense(nClasses))\n",
    "  modelCNN.add(Activation('softmax'))\n",
    "\n",
    "  # Optimiser and compiler\n",
    "  opt = SGD(learning_rate= learnRate, momentum= momentum)\n",
    "\n",
    "  modelCNN.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  batchSize = 32\n",
    "\n",
    "  # Running the CNN model\n",
    "  H = modelCNN.fit(trainData, trainLabels, \n",
    "                validation_data=(testData, testLabels),\n",
    "                batch_size= batchSize, epochs = numEpochs, verbose= 0)\n",
    "\n",
    "\n",
    "  # Plot the train/valid loss and train/valid accuracy \n",
    "  plot_train_curves(H.history)\n",
    "\n",
    "  # Modelling all the test data\n",
    "  predictionsCNN = modelCNN.predict(testData)\n",
    "  yPred = predictionsCNN.argmax(axis=1)\n",
    "\n",
    "  # Printing classification report\n",
    "  report = classification_report(testLabels.argmax(axis=1),\n",
    "                                yPred,\n",
    "                                target_names=[\"HII\",\"PNE\",\"RG\"])\n",
    "  print(report)\n",
    "\n",
    "  cmatrix = confusion_matrix(testLabels.argmax(axis=1), yPred)\n",
    "  plot_confusion_matrix(cmatrix, classes = ['HII', 'PNE', 'RG'],\n",
    "                        title = 'Classification Confusion Matrix', normalize=True)\n",
    "  print(cmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77106b37-58ad-430e-8c3e-980c71f0e03e",
   "metadata": {},
   "source": [
    "# fastai and pytorch comparison"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
